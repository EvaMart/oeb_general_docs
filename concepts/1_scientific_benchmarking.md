# Community-driven Scientific Benchmarking efforts

## Basic concepts

TODO

## Data flow and data sets

TODO

### Implementation in OpenEBench: architecture levels

OpenEBench scientific benchmarking architecture has three different levels that allow communities at different maturity stages to make use of the platform.

-   **Level 1** is used for the long-term storage of benchmarking events and challenges aiming at reproducibility and provenance.

-   **Level 2** allows the community to use benchmarking workflows to assess participants' performance. Those workflows compute one or more evaluation metrics given one or more reference datasets.

-   **Level 3** goes further by getting workflows specifications from participants, and then evaluating them in terms of technical and scientific performance. At this level, the whole benchmarking experiment is performed at OpenEBench; first, the predictions are made using the software provided by the participants, then, those predictions are evaluated with the benchmarking workflows, and, finally, the results are stored and visualized in the web server.

<img src="../media/image5.png" alt="OEB architecture levels" align="center" width="75%">

Importantly, each level makes use of the architecture defined in the previous level e.g. participants' data generated by workflows at Level 3
are evaluated using the metrics and reference datasets in Level 2, and the resulting data is stored following the data model in Level 1 for private and/or public consumption.

### User roles

TODO
