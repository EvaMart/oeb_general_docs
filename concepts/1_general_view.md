# General View

## Scientific architecture levels
OpenEBench scientific benchmarking architecture has three different
levels that allow communities at different maturity stages to make use
of the platform.

-   **Level 1** is used for the long-term storage of benchmarking events and challenges aiming at reproducibility and provenance.

-   **Level 2** allows the community to use benchmarking workflows to assess participants' performance. Those workflows compute one or more evaluation metrics given one or more reference datasets.

-   **Level 3** goes further by getting workflows specifications from participants, and then evaluating them in terms of technical and scientific performance. At this level, the whole benchmarking experiment is performed at OpenEBench; first, the predictions are made using the software provided by the participants, then, those predictions are evaluated with the benchmarking workflows, and, finally, the results are stored and visualized in the web server.

![1](../media/image5.png)

Importantly, each level makes use of the architecture defined in the
previous level e.g. participants' data generated by workflows at Level 3
are evaluated using the metrics and reference datasets in Level 2, and
the resulting data is stored following the data model in Level 1 for
private and/or public consumption.


## Glossary
